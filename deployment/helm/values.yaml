replicaCount: 3

image:
  repository: docker.io/your-dockerhub-namespace/your-repo
  tag: "latest"
  pullPolicy: IfNotPresent

imagePullSecrets: []  # e.g. [{ name: dockerhub-cred }]

nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  name: ""                          # leave empty to auto-name
  automount: true                   # required for IRSA
  irsa:
    enabled: true                   # <— turn on IRSA
    roleArn: arn:aws:iam::123456789012:role/referral-pulse-svc-role  # <— set your IAM role ARN
    audience: sts.amazonaws.com     # default audience
  annotations:
    # add any extra annotations you need here
    # example: foo: "bar"
  imagePullSecrets: [ ]                   # e.g. [{ name: dockerhub-cred }]

rbac:
  enabled: true                     # <— create Role/RoleBinding if app calls K8s API
  # Minimal read to ConfigMaps/Secrets. Adjust if needed.
  rules:
    - apiGroups: [""]
      resources: ["configmaps"]
      verbs: ["get","list","watch"]
    - apiGroups: [""]
      resources: ["secrets"]
      verbs: ["get","list","watch"]

podAnnotations: {}
podLabels: {}

podSecurityContext:
  runAsNonRoot: true
  seccompProfile: { type: RuntimeDefault }

containerSecurityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  capabilities:
    drop: ["ALL"]

service:
  type: ClusterIP
  port: 8080
  metricsPort: 8080
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/path: "/metrics"
    prometheus.io/port: "8080"

ingress:
  # Disabled - This service is accessed via Spring Cloud Gateway only
  # ALB → Spring Gateway → referral-pulse-svc (ClusterIP)
  enabled: false
  className: "alb"
  annotations:
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/healthcheck-path: /health
    alb.ingress.kubernetes.io/healthcheck-port: traffic-port
    alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80},{"HTTPS":443}]'
    alb.ingress.kubernetes.io/ssl-redirect: "443"
    alb.ingress.kubernetes.io/backend-protocol: HTTP
    alb.ingress.kubernetes.io/success-codes: "200-399"
  hosts:
    - host: api.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: tls-acm-placeholder
      hosts:
        - api.example.com

# ---- NetworkPolicy tuning
networkPolicy:
  enabled: true
  # Allow only Spring Cloud Gateway to reach this service
  # Update namespaceSelector/podSelector to match your Spring Gateway deployment
  allowFromIngressController:
    enabled: true
    namespaceSelector:
      matchLabels:
        kubernetes.io/metadata.name: default  # Change to your Spring Gateway namespace
    podSelector:
      matchLabels:
        app: spring-cloud-gateway  # Change to match your Spring Gateway pod labels

  # allow Prometheus to scrape /metrics
  allowFromPrometheus:
    enabled: true
    namespaceSelector:
      matchLabels:
        release: kube-prometheus-stack          # adapt to your Prometheus ns labels
    podSelector:
      matchLabels: {}

  # egress control
  egress:
    allowDns: true
    kubeDnsNamespace: kube-system
    kubeDnsSelector:
      k8s-app: kube-dns
    # allow OTEL collector (namespace/labels)
    allowOtel: true
    otelNamespaceSelector:
      matchLabels:
        name: otel
    otelPodSelector:
      matchLabels:
        app.kubernetes.io/name: otel-collector
    # If you need general outbound (e.g., S3/SQS/SNS), keep this true
    allowInternet: true

resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 200m
    memory: 256Mi

# ---- Worker Configuration (BullMQ Job Processors) ----
worker:
  # Enable worker deployment
  enabled: true

  # Number of worker replicas (BullMQ handles distributed locking)
  replicaCount: 2

  # Worker-specific log level (can be different from web pods)
  logLevel: "info"

  # Worker resources (typically lower than web pods)
  resources:
    limits:
      cpu: 300m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 256Mi

  # Worker pod security context (same as web pods)
  podSecurityContext:
    runAsNonRoot: true
    seccompProfile: { type: RuntimeDefault }

  # Worker container security context (same as web pods)
  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop: ["ALL"]

  # Worker node selector (can schedule on different nodes if needed)
  nodeSelector: {}

  # Worker tolerations
  tolerations: []

  # Worker affinity (ensure worker doesn't run on same node as web pods)
  affinity: {}

  # Extra environment variables for worker
  extraEnv: {}
    # OUTBOX_BATCH_SIZE: "100"
    # OUTBOX_CRON_INTERVAL: "*/5 * * * * *"

livenessProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3
  successThreshold: 1

readinessProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 10
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3
  successThreshold: 1

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 20
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 85

pdb:
  enabled: true
  minAvailable: 1

serviceMonitor:
  enabled: true
  interval: 15s
  scrapeTimeout: 10s
  labels: {}
  metricRelabelings: []
  relabelings: []

nodeSelector: {}
tolerations: []
affinity: {}
topologySpreadConstraints: []
migrations:
  enabled: true
  backoffLimit: 1
  ttlSecondsAfterFinished: 300
  # Optional: set to true if DB can take time to accept connections
  waitForDb: false
  # extra env (merged on top of envFrom)
  extraEnv: []

# -------- ConfigMap (non-sensitive env) --------
envVars:
  NODE_ENV: "production"
  APP_PORT: "8080"
  FRONTEND_DOMAIN: "https://app.example.com"
  BACKEND_DOMAIN: "https://api.example.com"
  API_PREFIX: "api"
  APP_FALLBACK_LANGUAGE: "en"
  APP_HEADER_LANGUAGE: "x-custom-lang"

  # Database
  DATABASE_TYPE: "postgres"
  DATABASE_HOST: "postgres.default.svc.cluster.local"
  DATABASE_PORT: "5432"
  DATABASE_NAME: "referral-db"
  DATABASE_USERNAME: "root"
  DATABASE_SYNCHRONIZE: "false"
  DATABASE_MAX_CONNECTIONS: "100"
  DATABASE_SSL_ENABLED: "false"
  DATABASE_LOGGING: "false"

  # Redis
  REDIS_HOST: "redis.default.svc.cluster.local"
  REDIS_PORT: "6379"
  REDIS_DB: "0"
  REDIS_TLS_ENABLED: "false"
  REDIS_KEY_PREFIX: "rp:"

  # AWS
  AWS_REGION: "eu-central-1"
  AWS_ENDPOINT: ""

  # S3
  AWS_S3_BUCKET: "referral-pulse-staging"
  AWS_S3_REGION: "eu-central-1"
  AWS_S3_ENDPOINT: ""

  # SQS Queues (individual queue URLs)
  SQS_QUEUE_CAMPAIGN_EVENTS: "https://sqs.eu-central-1.amazonaws.com/123456789012/campaign-events.fifo"
  SQS_QUEUE_REFERRAL_EVENTS: "https://sqs.eu-central-1.amazonaws.com/123456789012/referral-events.fifo"
  SQS_QUEUE_REWARD_EVENTS: "https://sqs.eu-central-1.amazonaws.com/123456789012/reward-events.fifo"
  SQS_QUEUE_USER_EVENTS: "https://sqs.eu-central-1.amazonaws.com/123456789012/user-events.fifo"
  SQS_QUEUE_NOTIFICATION_EVENTS: "https://sqs.eu-central-1.amazonaws.com/123456789012/notification-events.fifo"
  SQS_QUEUE_ANALYTICS_EVENTS: "https://sqs.eu-central-1.amazonaws.com/123456789012/analytics-events.fifo"
  SQS_QUEUE_WORKFLOW_EVENTS: "https://sqs.eu-central-1.amazonaws.com/123456789012/workflow-events.fifo"

  # SQS Configuration
  SQS_POLLING_ENABLED: "true"
  SQS_POLLING_WAIT_TIME_SECONDS: "20"
  SQS_POLLING_VISIBILITY_TIMEOUT: "60"
  SQS_POLLING_MAX_MESSAGES: "10"
  SQS_POLLING_TERMINATE_VISIBILITY_TIMEOUT: "0"

  # SNS
  SNS_TOPIC_ARN: "arn:aws:sns:eu-central-1:123456789012:campaign-notifications"

  # JWT/Auth
  AUTH_JWKS_URI: "https://auth.example.com/.well-known/jwks.json"
  AUTH_ISSUER: "https://auth.example.com/"
  AUTH_AUDIENCE: "referral-pulse-api"
  AUTH_ALGORITHMS: "RS256"
  AUTH_TENANT_CLAIM_PATH: "tenantId"
  AUTH_CLOCK_TOLERANCE: "30"
  AUTH_CACHE_ENABLED: "true"
  AUTH_CACHE_TTL: "600"

  # HTTP Client - Internal
  INTRA_HTTP_BASE_URL: "http://gateway.internal:3000"
  INTRA_HTTP_TIMEOUT_MS: "3000"
  INTRA_TENANT_HEADER: "x-tenant-id"
  INTRA_JWT_HEADER_NAME: "authorization"
  INTRA_HTTP_RETRIES: "3"
  INTRA_HTTP_RETRY_BASE_DELAY_MS: "200"
  INTRA_HTTP_RETRY_STATUSES: "429,502,503,504"

  # HTTP Client - Third Party
  TP_HTTP_BASE_URL: "https://thirdparty.example.com"
  TP_HTTP_TIMEOUT_MS: "5000"
  TP_HTTP_UA: "referral-pulse-svc/1.0"
  TP_HTTP_RETRIES: "2"
  TP_HTTP_RETRY_BASE_DELAY_MS: "400"
  TP_HTTP_RETRY_STATUSES: "429,500,502,503,504"

  # Circuit Breaker - Internal
  INTRA_CB_TIMEOUT_MS: "2500"
  INTRA_CB_VOLUME_THRESHOLD: "20"
  INTRA_CB_ERR_PCT: "50"
  INTRA_CB_RESET_TIMEOUT_MS: "10000"

  # Circuit Breaker - Third Party
  TP_CB_TIMEOUT_MS: "3500"
  TP_CB_VOLUME_THRESHOLD: "20"
  TP_CB_ERR_PCT: "50"
  TP_CB_RESET_TIMEOUT_MS: "15000"

  # Metrics
  METRICS_ENABLED: "true"
  METRICS_ENDPOINT: "/metrics"

  # OpenTelemetry
  OTEL_ENABLED: "true"
  OTEL_SERVICE_NAME: "referral-pulse-svc"
  OTEL_SERVICE_VERSION: "1.0.0"
  OTEL_EXPORTER_OTLP_ENDPOINT: "http://otel-collector.otel.svc.cluster.local:4318"
  OTEL_EXPORTER_OTLP_PROTOCOL: "http/protobuf"
  OTEL_EXPORTER_OTLP_HEADERS: ""

  # Logging
  LOGGING_LEVEL: "info"
  LOGGING_PRETTY: "false"

  # ClickHouse (Analytics)
  CH_URL: "http://clickhouse:8123"
  CH_USERNAME: "sa"
  CH_DATABASE: "analytics"

# -------- Secret (sensitive env) --------
# Note: AWS credentials (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY) are NOT included
# because IRSA (IAM Roles for Service Accounts) is enabled for this service.
# The service account is annotated with eks.amazonaws.com/role-arn.
secretVars:
  # Database
  DATABASE_PASSWORD: "your-db-password"

  # Redis
  REDIS_USERNAME: ""
  REDIS_PASSWORD: ""

  # ClickHouse
  CH_PASSWORD: "sa"

  # Third Party API Keys (if needed)
  TP_API_KEY: ""

# Extra manual envs (merged over envFrom)
extraEnv: []
